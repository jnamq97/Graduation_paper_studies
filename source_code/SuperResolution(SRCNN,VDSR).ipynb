{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SuperResolution(SRCNN,VDSR).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RFLYWDobn8hE"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"SA1g6LQE4ofj"},"source":["import os\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import *\n","import torch\n","import math \n","from os.path import join\n","import torch.utils.data as data\n","import numpy as np\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageOps\n","import random\n","from random import randrange\n","from math import sqrt\n","\n","class ConvBlock(torch.nn.Module):\n","    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation='prelu', norm=None):\n","        super(ConvBlock, self).__init__()\n","        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n","\n","        self.norm = norm\n","        if self.norm =='batch':\n","            self.bn = torch.nn.BatchNorm2d(output_size)\n","        elif self.norm == 'instance':\n","            self.bn = torch.nn.InstanceNorm2d(output_size)\n","\n","        self.activation = activation                 #activation 함수 결정\n","        if self.activation == 'relu':\n","            self.act = torch.nn.ReLU(True)\n","        elif self.activation == 'prelu':\n","            self.act = torch.nn.PReLU()\n","        elif self.activation == 'lrelu':\n","            self.act = torch.nn.LeakyReLU(0.2, True)\n","        elif self.activation == 'tanh':\n","            self.act = torch.nn.Tanh()\n","        elif self.activation == 'sigmoid':\n","            self.act = torch.nn.Sigmoid()\n","\n","    def forward(self, x):\n","        if self.norm is not None:\n","            out = self.bn(self.conv(x))\n","        else:\n","            out = self.conv(x)\n","\n","        if self.activation is not None:\n","            return self.act(out)\n","        else:\n","            return out\n","\n","class SRCNN(nn.Module):\n","    def __init__(self, num_channels, base_filter, scale_factor):\n","        super(SRCNN, self).__init__()\n","\n","        # Initial Feature Extraction\n","        self.layer1 = ConvBlock(num_channels, base_filter, kernel_size=9, stride=1, padding=4, activation='relu', norm=None)\n","        self.layer2 = ConvBlock(base_filter, base_filter // 2, kernel_size=1, stride=1, padding=0, activation='relu', norm=None)\n","        self.layer3 = ConvBlock(base_filter // 2, 3, kernel_size=5, stride=1, padding=2, activation=None, norm=None)\n","\n","        for m in self.modules():\n","            classname = m.__class__.__name__\n","            if classname.find('Conv2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif classname.find('ConvTranspose2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        f1 = self.layer1(x)\n","        f2 = self.layer2(f1)\n","        y = self.layer3(f2)\n","\n","        return y\n","\n","class Conv_ReLU_Block(nn.Module):\n","    def __init__(self):\n","        super(Conv_ReLU_Block, self).__init__()\n","        self.conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self, x):\n","        return self.relu(self.conv(x))\n","\n","class VDSR(nn.Module):\n","    def __init__(self):\n","        super(VDSR, self).__init__()\n","        self.residual_layer = self.make_layer(Conv_ReLU_Block, 5)            #레이어에 5번 \n","        self.input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.output = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","    \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, sqrt(2. / n))\n","                \n","    def make_layer(self, block, num_of_layer):        \n","        layers = []\n","        for _ in range(num_of_layer):\n","            layers.append(block())\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.input(x))\n","        out = self.residual_layer(out)\n","        out = self.output(out)\n","        out = torch.add(out,residual)\n","        return out\n","\n","\n","#2022/04/27 추가 squeeze and excitation module##############################\n","class SELayer(nn.Module):\n","    def __init__(self, channel, reduction=16):\n","        super(SELayer, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Sequential(\n","            nn.Linear(channel, channel // reduction, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(channel // reduction, channel, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        b, c, _, _ = x.size()\n","        y = self.avg_pool(x).view(b, c)\n","        y = self.fc(y).view(b, c, 1, 1)\n","        return x * y.expand_as(x)\n","\n","\n","class VDSR_SE(nn.Module):\n","    def __init__(self, reduction=16):\n","        super(VDSR_SE, self).__init__()\n","        self.residual_layer = self.make_layer(Conv_ReLU_Block, 5)            #레이어에 5번 \n","        self.input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.output = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.se = SELayer(64)\n","    \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, sqrt(2. / n))\n","                \n","    def make_layer(self, block, num_of_layer):        \n","        layers = []\n","        for _ in range(num_of_layer):\n","            layers.append(block())\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.input(x))\n","        out = self.residual_layer(out)\n","        out = self.se(out)\n","        out = self.output(out)\n","        out = torch.add(out,residual)\n","        return out\n","#####################################################################\n","\n","def is_image_file(filename):\n","    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\",\".bmp\"])\n","\n","\n","def load_img(filepath):\n","    img = Image.open(filepath).convert('RGB')\n","    #y, _, _ = img.split()\n","    return img\n","\n","def rescale_img(img_in, scale):\n","    size_in = img_in.size\n","    new_size_in = tuple([int(x * scale) for x in size_in])\n","    img_in = img_in.resize(new_size_in, resample=Image.BICUBIC)\n","    return img_in\n","\n","def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix=-1, iy=-1):\n","    (ih, iw) = img_in.size\n","    (th, tw) = (scale * ih, scale * iw)\n","\n","    patch_mult = scale #if len(scale) > 1 else 1\n","    tp = patch_mult * patch_size\n","    ip = tp // scale\n","\n","    if ix == -1:\n","        ix = random.randrange(0, iw - ip + 1)\n","    if iy == -1:\n","        iy = random.randrange(0, ih - ip + 1)\n","\n","    (tx, ty) = (scale * ix, scale * iy)\n","\n","    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n","    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n","    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n","                \n","    info_patch = {\n","        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n","\n","    return img_in, img_tar, img_bic, info_patch\n","\n","def augment(img_in, img_tar, img_bic, flip_h=True, rot=True):\n","    info_aug = {'flip_h': False, 'flip_v': False, 'trans': False}\n","    \n","    if random.random() < 0.5 and flip_h:\n","        img_in = ImageOps.flip(img_in)\n","        img_tar = ImageOps.flip(img_tar)\n","        img_bic = ImageOps.flip(img_bic)\n","        info_aug['flip_h'] = True\n","\n","    if rot:\n","        if random.random() < 0.5:\n","            img_in = ImageOps.mirror(img_in)\n","            img_tar = ImageOps.mirror(img_tar)\n","            img_bic = ImageOps.mirror(img_bic)\n","            info_aug['flip_v'] = True\n","        if random.random() < 0.5:\n","            img_in = img_in.rotate(180)\n","            img_tar = img_tar.rotate(180)\n","            img_bic = img_bic.rotate(180)\n","            info_aug['trans'] = True\n","            \n","    return img_in, img_tar, img_bic, info_aug\n","    \n","class DatasetFromFolder(data.Dataset):\n","    def __init__(self, image_dir, patch_size, upscale_factor, data_augmentation, transform=None):\n","        super(DatasetFromFolder, self).__init__()\n","        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n","        self.patch_size = patch_size\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","        self.data_augmentation = data_augmentation\n","\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        \n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC)       \n","        bicubic = rescale_img(input, self.upscale_factor)\n","        \n","        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor)\n","        \n","        if self.data_augmentation:\n","            input, target, bicubic, _ = augment(input, target, bicubic)\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","                \n","        return input, target, bicubic\n","\n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","class DatasetFromFolderEval(data.Dataset):\n","    def __init__(self, lr_dir, upscale_factor, transform=None):\n","        super(DatasetFromFolderEval, self).__init__()\n","        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        _, file = os.path.split(self.image_filenames[index])\n","\n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC)       \n","        bicubic = rescale_img(input, self.upscale_factor)\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","            \n","        return input, bicubic, target, file\n","      \n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","\n","def transform():\n","    return Compose([\n","        ToTensor(),\n","    ])\n","\n","def get_training_set(data_dir, hr, upscale_factor, patch_size, data_augmentation):\n","    hr_dir = join(data_dir, hr)\n","    return DatasetFromFolder(hr_dir,patch_size, upscale_factor, data_augmentation,\n","                             transform=transform())\n","\n","def get_eval_set(lr_dir, upscale_factor):\n","    return DatasetFromFolderEval(lr_dir, upscale_factor,\n","                             transform=transform())\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZULxzu4Sn-Vp"},"source":["#Training\n"]},{"cell_type":"code","metadata":{"id":"7HV0P4OE3azY","colab":{"base_uri":"https://localhost:8080/","height":543},"executionInfo":{"status":"error","timestamp":1651031325936,"user_tz":-540,"elapsed":26474,"user":{"displayName":"‍김태현[ 대학원석사과정재학 / 전기전자공학과 ]","userId":"10449546666937114434"}},"outputId":"b1ae3cb7-81e2-4d5e-a1cf-3d6497636368"},"source":["from __future__ import print_function\n","import argparse\n","from math import log10\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import pdb\n","import socket\n","import time\n","import easydict\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"batchSize\": 32,           # batch size - 한번에 training할 patch의 숫자\n","    \"lr\": 1e-3,                # learning rate\n","    \"upscale_factor\": 2,       # Upscale 정도 - 2배, 4배\n","    \"patch_size\": 64,         # patch 크기\n","    \"feature_number\": 64,     # SRCNN model에서 사용할 feature 숫자\n","    \n","    \"start_iter\": 1,           \n","    \"nEpochs\": 200,            # training 횟수\n","    \"snapshots\": 20,           # weight 저장 주기\n","   \n","    \"data_dir\":\"/content/gdrive/My Drive/SRCNN/data/train/\", # dataset 저장 위치\n","    \"hr_train_dataset\": \"DIV2K_train_HR\", # training에 사용할 dataset 종류\n","\n","    \"model_type\": \"VDSR_SE\",         # 모델이름\n","\n","    \"save_folder\": \"/content/gdrive/My Drive/SRCNN/weights/\", # weight 저장 위치\n","    \n","\n","    \"pretrained_sr\": \"/content/gdrive/My Drive/SRCNN/weights/ckpt_diff11_label\",\n","    \"pretrained\": False,\n","    \"data_augmentation\": False,\n","    \"residual\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 1,\n","    \"seed\": 123,\n","    \"gpus\": 1,\n","    \"prefix\": \"tpami_residual_filter8\"})\n","\n","gpus_list = range(opt.gpus)\n","hostname = str(socket.gethostname())\n","cudnn.benchmark = True\n","print(opt)\n","\n","def train(epoch):\n","    epoch_loss = 0\n","    model.train()\n","    for iteration, batch in enumerate(training_data_loader, 1):\n","        _, target, bicubic = Variable(batch[0]), Variable(batch[1]), Variable(batch[2])\n","        if cuda:\n","            # input = input.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","\n","        optimizer.zero_grad()  #gradient를 초기에 0으로 설정\n","        t0 = time.time()\n","        prediction = model(bicubic)\n","\n","        if opt.residual:\n","            prediction = prediction + bicubic\n","\n","        loss = criterion(prediction, target)\n","        t1 = time.time()\n","        epoch_loss += loss.data\n","        loss.backward()  #backward 함수는 어떤 스칼라 값에 대한 출력 텐서의 변화도(gradient)를 전달받고, 동일한 스칼라 값에 대한 입력 텐서의 변화도를 계산합니다.\n","        optimizer.step() #변화도를 계산한 뒤에는 optimizer.step()을 호출하여 backpropagation 단계에서 수집된 변화도로 매개변수를 조정합니다.\n","\n","        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, iteration, len(training_data_loader), loss.data, (t1 - t0)))\n","\n","    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n","\n","def print_network(net):\n","    num_params = 0\n","    for param in net.parameters():\n","        num_params += param.numel()\n","    print(net)\n","    print('Total number of parameters: %d' % num_params)\n","\n","def checkpoint(epoch):\n","    model_out_path = opt.save_folder+hostname+\"_epoch_{}.pth\".format(epoch)\n","    torch.save(model.state_dict(), model_out_path)\n","    print(\"Checkpoint saved to {}\".format(model_out_path))\n","\n","if __name__ == '__main__':\n","\n","    cuda = opt.gpu_mode\n","    if cuda and not torch.cuda.is_available():\n","        raise Exception(\"No GPU found, please run without --cuda\")\n","\n","    torch.manual_seed(opt.seed)\n","    if cuda:\n","        torch.cuda.manual_seed(opt.seed)\n","\n","    print('===> Loading datasets')            # dataset을 로드한다.\n","    train_set = get_training_set(opt.data_dir, opt.hr_train_dataset, opt.upscale_factor, opt.patch_size, opt.data_augmentation)\n","    training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)       #Dataset 은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다.\n","                                                                                                                                # 모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고, 매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고, Python의 multiprocessing 을 사용하여 데이터 검색 속도를 높이려고 합니다.\n","                                                                                                                                #train 할 데이터를 불러와서 batch size만큼을 반환하기 위해 iterate를 한다.\n","\n","    # 모델 종류 구분\n","    print('===> Building model ', opt.model_type)\n","    if opt.model_type == 'SRCNN':\n","        model = SRCNN(num_channels=3, base_filter=opt.feature_number, scale_factor=opt.upscale_factor)\n","    elif opt.model_type == 'VDSR':\n","        model = VDSR()\n","    elif opt.model_type == 'VDSR_SE':\n","        model = VDSR_SE()\n","        \n","        model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = nn.L1Loss()\n","    # pretrained 면 dir에 저장된 위치를 알려라\n","    if opt.pretrained:\n","        model_name = os.path.join(opt.save_folder + opt.pretrained_sr)\n","        if os.path.exists(model_name):\n","            #model= torch.load(model_name, map_location=lambda storage, loc: storage)\n","            model.load_state_dict(torch.load(model_name, map_location=lambda storage, loc: storage))\n","            print('Pre-trained SR model is loaded.')\n","\n","    if cuda:\n","        model = model.cuda(gpus_list[0])\n","        criterion = criterion.cuda(gpus_list[0])\n","\n","    optimizer = optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8) # gradient 조절\n","\n","    for epoch in range(opt.start_iter, opt.nEpochs + 1):\n","        train(epoch)\n","\n","        # learning rate is decayed by a factor of 10 every half of total epochs\n","        if (epoch+1) % (opt.nEpochs/2) == 0:\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] /= 10.0\n","            print('Learning rate decay: lr={}'.format(optimizer.param_groups[0]['lr']))\n","\n","        if (epoch+1) % (opt.snapshots) == 0:\n","            checkpoint(epoch)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'batchSize': 32, 'lr': 0.001, 'upscale_factor': 2, 'patch_size': 64, 'feature_number': 64, 'start_iter': 1, 'nEpochs': 200, 'snapshots': 20, 'data_dir': '/content/gdrive/My Drive/SRCNN/data/train/', 'hr_train_dataset': 'DIV2K_train_HR', 'model_type': 'VDSR_SE', 'save_folder': '/content/gdrive/My Drive/SRCNN/weights/', 'pretrained_sr': '/content/gdrive/My Drive/SRCNN/weights/ckpt_diff11_label', 'pretrained': False, 'data_augmentation': False, 'residual': False, 'gpu_mode': True, 'threads': 1, 'seed': 123, 'gpus': 1, 'prefix': 'tpami_residual_filter8'}\n","===> Loading datasets\n","===> Building model  VDSR_SE\n","===> Epoch[1](1/25): Loss: 0.2670 || Timer: 0.9949 sec.\n","===> Epoch[1](2/25): Loss: 0.4198 || Timer: 0.0024 sec.\n","===> Epoch[1](3/25): Loss: 0.1438 || Timer: 0.0030 sec.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-358722d43227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEpochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# learning rate is decayed by a factor of 10 every half of total epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-358722d43227>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicubic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"rbEr5gACDNWp"}},{"cell_type":"code","metadata":{"id":"SpSPqBoHE8vA","colab":{"base_uri":"https://localhost:8080/","height":414},"executionInfo":{"status":"error","timestamp":1651214425362,"user_tz":-540,"elapsed":7359,"user":{"displayName":"정남교","userId":"09026629101721319212"}},"outputId":"bcfe2174-fd58-4ed9-dadc-85d8f9fe8385"},"source":["\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from functools import reduce\n","from math import log10\n","\n","# from scipy.misc import imsave\n","import scipy.io as sio\n","import time\n","import cv2\n","import easydict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"testBatchSize\": 1, \n","    \"self_ensemble\": False,\n","    \"chop_forward\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 1,\n","    \"seed\": 123,\n","    \"gpus\": 1,\n","    \"upscale_factor\": 2,\n","\n","    \"input_dir\":\"/content/gdrive/My Drive/SRCNN/data/test/\",  # test dataset 불러올위치\n","    \"test_dataset\": \"Set5\",                             # 사용할 test dataset\n","\n","    \"output\": \"/content/gdrive/My Drive/SRCNN/Results/\", # 결과영상 저장위치\n","\n","    \"model_type\": \"VDSR_SE\",\n","    \"residual\": False,\n","    \"model\": \"/content/gdrive/My Drive/SRCNN/weights/ac040091dff2_epoch_59.pth\"})  # test에 사용할 weight 불러올 위치 ac040091dff2_epoch_59.pth\n","\n","\n","gpus_list=range(opt.gpus)\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","torch.manual_seed(opt.seed)\n","criterion = nn.MSELoss()\n","\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    criterion = criterion.cuda(gpus_list[0])\n","\n","\n","print('===> Loading datasets')\n","test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n","testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n","\n","print('===> Building model')\n","\n","    #model = SRCNN(num_channels=3, base_filter=64, scale_factor=opt.upscale_factor)\n","model = VDSR()\n","model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","model.load_state_dict(torch.load(opt.model, map_location=lambda storage, loc: storage))  # state_dict를 불러 온 후, 모델에 저장\n","print('Pre-trained SR model is loaded.')\n","\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","\n","def eval():\n","    avg_psnr = 0\n","    psnr_sq = 0\n","    model.eval()\n","    for batch in testing_data_loader:\n","        with torch.no_grad():\n","            input, bicubic, target, name = Variable(batch[0]), Variable(batch[1]), Variable(batch[2]), batch[3]\n","        if cuda:\n","            input = input.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","\n","        t0 = time.time()\n","        if opt.chop_forward:\n","            with torch.no_grad():\n","                prediction = chop_forward(input, model, opt.upscale_factor)\n","        else:\n","            if opt.self_ensemble:\n","                with torch.no_grad():\n","                    prediction = x8_forward(input, model)\n","            else:\n","                with torch.no_grad():\n","                    prediction = model(bicubic)\n","                \n","        if opt.residual:\n","            prediction = prediction + bicubic\n","\n","        mse = criterion(prediction, target)\n","        psnr = 10 * log10(1 / mse.item())\n","        avg_psnr += psnr\n","        psnr_sq += psnr*psnr\n","\n","        t1 = time.time()\n","        print(\"===> Processing: %s || Timer: %.4f sec. PSNR : %.4f\" % (name[0], (t1 - t0), psnr))\n","        # save_img(prediction.cpu().data, name[0])\n","        save_img(bicubic.cpu().data, name[0])\n","        # save_img(target.cpu().data, name[0])\n","        average = avg_psnr/len(testing_data_loader)\n","        variance = psnr_sq/len(testing_data_loader)-average*average\n","    print(\"===> Processing Done, Average PSNR : %.4f\" % (average))\n","    print(\"===>PSNR Variance : %.4f\" % (variance))\n","def save_img(img, img_name):\n","    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n","    # save img\n","    save_dir=os.path.join(opt.output,opt.test_dataset)\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    save_fn = save_dir +'/'+ img_name\n","    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n","\n","def x8_forward(img, model, precision='single'):\n","    def _transform(v, op):\n","        if precision != 'single': v = v.float()\n","\n","        v2np = v.data.cpu().numpy()\n","        if op == 'vflip':\n","            tfnp = v2np[:, :, :, ::-1].copy()\n","        elif op == 'hflip':\n","            tfnp = v2np[:, :, ::-1, :].copy()\n","        elif op == 'transpose':\n","            tfnp = v2np.transpose((0, 1, 3, 2)).copy()\n","        \n","        ret = torch.Tensor(tfnp).cuda()\n","\n","        if precision == 'half':\n","            ret = ret.half()\n","        elif precision == 'double':\n","            ret = ret.double()\n","\n","        with torch.no_grad():\n","            ret = Variable(ret)\n","\n","        return ret\n","\n","    inputlist = [img]\n","    for tf in 'vflip', 'hflip', 'transpose':\n","        inputlist.extend([_transform(t, tf) for t in inputlist])\n","\n","    outputlist = [model(aug) for aug in inputlist]\n","    for i in range(len(outputlist)):\n","        if i > 3:\n","            outputlist[i] = _transform(outputlist[i], 'transpose')\n","        if i % 4 > 1:\n","            outputlist[i] = _transform(outputlist[i], 'hflip')\n","        if (i % 4) % 2 == 1:\n","            outputlist[i] = _transform(outputlist[i], 'vflip')\n","    \n","    output = reduce((lambda x, y: x + y), outputlist) / len(outputlist)\n","\n","    return output\n","    \n","def chop_forward(x, model, scale, shave=8, min_size=80000, nGPUs=opt.gpus):\n","    b, c, h, w = x.size()\n","    h_half, w_half = h // 2, w // 2\n","    h_size, w_size = h_half + shave, w_half + shave\n","    inputlist = [\n","        x[:, :, 0:h_size, 0:w_size],\n","        x[:, :, 0:h_size, (w - w_size):w],\n","        x[:, :, (h - h_size):h, 0:w_size],\n","        x[:, :, (h - h_size):h, (w - w_size):w]]\n","\n","    if w_size * h_size < min_size:\n","        outputlist = []\n","        for i in range(0, 4, nGPUs):\n","            with torch.no_grad():\n","                input_batch = torch.cat(inputlist[i:(i + nGPUs)], dim=0)\n","            if opt.self_ensemble:\n","                with torch.no_grad():\n","                    output_batch = x8_forward(input_batch, model)\n","            else:\n","                with torch.no_grad():\n","                    output_batch = model(input_batch)\n","            outputlist.extend(output_batch.chunk(nGPUs, dim=0))\n","    else:\n","        outputlist = [\n","            chop_forward(patch, model, scale, shave, min_size, nGPUs)\n","            for patch in inputlist]\n","\n","    h, w = scale * h, scale * w\n","    h_half, w_half = scale * h_half, scale * w_half\n","    h_size, w_size = scale * h_size, scale * w_size\n","    shave *= scale\n","\n","    with torch.no_grad():\n","        output = Variable(x.data.new(b, c, h, w))\n","\n","    output[:, :, 0:h_half, 0:w_half] \\\n","        = outputlist[0][:, :, 0:h_half, 0:w_half]\n","    output[:, :, 0:h_half, w_half:w] \\\n","        = outputlist[1][:, :, 0:h_half, (w_size - w + w_half):w_size]\n","    output[:, :, h_half:h, 0:w_half] \\\n","        = outputlist[2][:, :, (h_size - h + h_half):h_size, 0:w_half]\n","    output[:, :, h_half:h, w_half:w] \\\n","        = outputlist[3][:, :, (h_size - h + h_half):h_size, (w_size - w + w_half):w_size]\n","\n","    return output\n","\n","##Eval Start!!!!\n","if __name__ == '__main__':\n","    eval()\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d532b19ecc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0measydict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m opt = easydict.EasyDict({ \n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 128\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]}]}