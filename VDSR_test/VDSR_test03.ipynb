{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VDSR_test03.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMu8N8unh8ujX2Isd3QmoyZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"k_ydz62ti5YN"}},{"cell_type":"markdown","source":["VDSR\\\n","epoch : 80\\\n","filter : 32\\\n","layers : 5\\\n","loss function : L1"],"metadata":{"id":"klLEm8yPjXai"}},{"cell_type":"code","source":["import os\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import *\n","import torch\n","import math \n","from os.path import join\n","import torch.utils.data as data\n","import numpy as np\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageOps\n","import random\n","from random import randrange\n","from math import sqrt\n","       \n","#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------        \n","class Conv_ReLU_Block(nn.Module): #used for VDSR\n","    def __init__(self):\n","        super(Conv_ReLU_Block, self).__init__() #super를 안해주면 부모 클래스의 init 함수가 Overriding 된다.\n","        self.conv = nn.Conv2d(in_channels=32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1, bias =False)\n","        self.relu = nn.ReLU(inplace=True) #inplace 연산은 결과값을 새로운 변수에 값을 저장하는 대신 기존의 데이터를 대체하는것\n","    def forward(self, x):\n","        return self.relu(self.conv(x)) \n","    \n","class VDSR(nn.Module):\n","    def __init__(self):\n","        super(VDSR, self).__init__()\n","        self.input = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.residual_layer = self.make_layer(Conv_ReLU_Block, 5)\n","        self.output = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        \n","        for m in self.modules(): #모델의 모듈을 불러온다\n","            if isinstance(m, nn.Conv2d): #만약 그 모듈이 Conv2d이면 초기화를 해준다.\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, sqrt(2. / n)) #weight initialization (평균, 표준편차)\n","    def make_layer(self, block, num_of_layer):\n","        layers=[]\n","        for _ in range(num_of_layer):\n","            layers.append(block())\n","        return nn.Sequential(*layers) #*layers -> unpacking(deal with list elements separately)\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.input(x))\n","        out = self.residual_layer(out)\n","        out = self.output(out)\n","        out = torch.add(out, residual)\n","        return out\n","#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n","def is_image_file(filename): #image file 인지 확인해줌\n","    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\",\".bmp\"])\n","    \n","def load_img(filepath):\n","    img = Image.open(filepath).convert('RGB')\n","    return img\n","    \n","def rescale_img(img_in, scale):\n","    size_in = img_in.size\n","    new_size_in = tuple([int(x * scale) for x in size_in])\n","    img_in = img_in.resize(new_size_in, resample = Image.BICUBIC)\n","    return img_in\n","    \n","def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix= -1, iy = -1): \n","    #잘 이해 안됨. 각 크기가 맞는 랜덤한 패치를 return 하는거?\n","    (ih, iw) = img_in.size\n","    (th, tw) = (scale * ih, scale * iw)\n","    \n","    patch_mult = scale\n","    tp = patch_mult * patch_size\n","    ip = tp // scale\n","    \n","    if ix == -1:\n","        ix = random.randrange(0, iw - ip + 1)\n","    if iy == -1:\n","        iy = random.randrange(0, ih - ip + 1)\n","\n","    (tx, ty) = (scale * ix, scale * iy)\n","\n","    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n","    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n","    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n","                \n","    info_patch = {\n","        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n","\n","    return img_in, img_tar, img_bic, info_patch\n","\n","def augment(img_in, img_tar, img_bic, flip_h=True, rot=True):\n","    info_aug = {'flip_h': False, 'flip_v': False, 'trans': False}\n","    \n","    if random.random() < 0.5 and flip_h :\n","        img_in = ImageOps.flip(img_in)\n","        img_tar = ImageOps.flip(img_tar)\n","        img_bic = ImageOps.flip(img_bic)\n","        info_aug['flip_h'] = True\n","    if rot : \n","        if random.random() < 0.5:\n","            img_in = ImageOps.mirror(img_in)\n","            img_tar = ImageOps.mirror(img_tar)\n","            img_bic = ImageOps.mirror(img_bic)\n","            info_aug['flip_v'] = True\n","        if random.random() < 0.5:\n","            img_in = img_in.rotate(180)\n","            img_tar = img_tar.rotate(180)\n","            img_bic = img_bic.rotate(180)\n","            info_aug['trans'] = True\n","    return img_in, img_tar, img_bic, info_aug\n","    \n","#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","class DatasetFromFolder(data.Dataset): #training dataset class\n","    def __init__(self, image_dir, patch_size, upscale_factor, data_augmentation, transform=None):\n","        super(DatasetFromFolder, self).__init__()\n","        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]  #image file들의 name(dir)을 담은 리스트\n","        self.patch_size = patch_size\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","        self.data_augmentation = data_augmentation\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        \n","        input = target.resize((int(target.size[0]/self.upscale_factor), int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n","        bicubic = rescale_img(input, self.upscale_factor) #upscale_factor로 줄이고 다시 늘려서 LR image 를 만든것 같다.(방식은 bicubic)\n","        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor) #crop된 image로 다시 정의함\n","        \n","        if self.data_augmentation :\n","            input, target, bicubic, _ = augment(input, target, bicubic)\n","        if self.transform :\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","            \n","        return input, target, bicubic #그럼 최종 return은 patch(crop된 image)인 건가?\n","    \n","    def __len__(self):\n","        return len(self.image_filenames)\n","    \n","class DatasetFromFolderEval(data.Dataset): #test dataset class\n","    \n","    def __init__(self, lr_dir, upscale_factor, transform = None):\n","        super(DatasetFromFolderEval, self).__init__()\n","        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        _, file = os.path.split(self.image_filenames[index])  #주소 split해서 파일이름을 가지는 file 변수 정의(head, tail) tail은 마지막 구성요소\n","        \n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC)\n","        bicubic = rescale_img(input, self.upscale_factor)\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","        \n","        return input, bicubic, target, file\n","        \n","    def __len__(self):\n","        return len(self.image_filenames)\n","        \n","def transform():\n","    return Compose([\n","        ToTensor(),\n","    ])\n","def get_training_set(data_dir, hr, upscale_factor, patch_size, data_augmentation):\n","    hr_dir = join(data_dir, hr)\n","    return DatasetFromFolder(hr_dir, patch_size, upscale_factor, data_augmentation, \n","                            transform = transform())\n","def get_eval_set(lr_dir, upscale_factor):\n","    return DatasetFromFolderEval(lr_dir, upscale_factor,\n","                                transform = transform())"],"metadata":{"id":"DGkEWSnVjDBQ","executionInfo":{"status":"ok","timestamp":1649743633408,"user_tz":-540,"elapsed":7063,"user":{"displayName":"정남교","userId":"09026629101721319212"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"x0e2x-4Ti5dp"}},{"cell_type":"code","source":["from __future__ import print_function\n","import argparse\n","from math import log10\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import pdb\n","import socket\n","import time\n","import easydict\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt  = easydict.EasyDict({ \n","    \"batchSize\": 32,           # batch size - 한번에 training할 patch의 숫자\n","    \"lr\": 1e-3,                # learning rate\n","    \"upscale_factor\": 2,       # Upscale 정도 - 2배, 4배\n","    \"patch_size\": 64,         # patch 크기\n","    \"feature_number\": 64,     # SRCNN model에서 사용할 feature 숫자\n","    \n","    \"start_iter\": 1,           \n","    \"nEpochs\": 80,            # training 횟수\n","    \"snapshots\": 20,           # weight 저장 주기\n","   \n","    \"data_dir\":\"/content/gdrive/My Drive/study/VDSR/data/train/\", # dataset 저장 위치\n","    \"hr_train_dataset\": \"DIV2K_train_HR\", # training에 사용할 dataset 종류\n","\n","    \"model_type\": \"VDSR\",         # 모델이름\n","\n","    \"save_folder\": \"/content/gdrive/My Drive/study/VDSR/weights/\", # weight 저장 위치\n","    \n","\n","    \"pretrained_sr\": \"/content/gdrive/My Drive/study/VDSR/weights/ckpt_diff11_label\",\n","    \"pretrained\": False,\n","    \"data_augmentation\": False,\n","    \"residual\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 1,\n","    \"seed\": 123,\n","    \"gpus\": 1,\n","    \"prefix\": \"tpami_residual_filter8\"})\n","\n","gpus_list = range(opt.gpus)\n","hostname = str(socket.gethostname) #저장 파일명으로 사용하려고 그냥 가져온것\n","cudnn.benchmark = True # cuDNN이 최적의 알고리즘을 선택하도록 해줌(잘 이해 안됨)\n","print(opt)\n","\n","def train(epoch):\n","    epoch_loss = 0\n","    model.train()\n","    for iteration, batch in enumerate(training_data_loader, 1): #시작 인덱스(i)를 1부터 세겠다는 뜻\n","        _, target, bicubic = Variable(batch[0]), Variable(batch[1]), Variable(batch[2]) #torch.autograd.Variable 하는 이유??\n","        if cuda : \n","             # input = input.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","        optimizer.zero_grad()\n","        t0 = time.time()\n","        prediction = model(bicubic)\n","        \n","        if opt.residual :\n","            prediction = prediction + bicubic\n","        \n","        loss = criterion(prediction, target)\n","        t1 = time.time()\n","        epoch_loss += loss.data\n","        loss.backward()\n","        optimizer.step()\n","        \n","        print(\"===> Epoch[{}]({}/{}) : Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, iteration, len(training_data_loader), loss.data, (t1-t0))) \n","    print(\"===> Epoch {} Complete : Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n"," #-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------       \n","def print_network(net):  #어디에 쓰임????\n","    num_params = 0\n","    for param in net.parameters():\n","        num_params += param.numel()\n","    print(net)\n","    print('Total number of parameters: %d' % num_params)\n","    \n","def checkpoint(epoch): #check point 마다 weight를 저장해줌 (모델의 매개변수들을 저장해준다)\n","    model_out_path = opt.save_folder+hostname+\"_epoch_{}.pth\".format(epoch)\n","    torch.save(model.state_dict(), model_out_path)\n","    print(\"Checkpoint saved to {}\".format(model_out_path))\n","#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------    \n","if __name__ == '__main__':\n","    \n","    cuda = opt.gpu_mode\n","    if cuda and not torch.cuda.is_available():\n","        raise Exception(\"No GPU found, please run without --cuda\")\n","    torch.manual_seed(opt.seed)\n","    if cuda : \n","        torch.cuda.manual_seed(opt.seed)\n","    \n","    print('===> Loading datasets')\n","    train_set = get_training_set(opt.data_dir, opt.hr_train_dataset, opt.upscale_factor, opt.patch_size, opt.data_augmentation)\n","    training_data_loader = DataLoader(dataset = train_set, num_workers=opt.threads, batch_size = opt.batchSize, shuffle=True)\n","    \n","    print('===> Building model ', opt.model_type)\n","    if opt.model_type == 'VDSR':\n","        model = VDSR()\n","        model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = nn.L1Loss()   #Loss function\n","    \n","    if opt.pretrained:\n","        model_name = os.path.join(opt.save_folder + opt.pretrained_sr)\n","        if os.path.exists(model_name):\n","            #model= torch.load(model_name, map_location=lambda storage, loc: storage)\n","            model.load_state_dict(torch.load(model_name, map_location=lambda storage, loc: storage))\n","            print('Pre-trained SR model is loaded.')  \n","    if cuda:\n","        model = model.cuda(gpus_list[0])\n","        criterion = criterion.cuda(gpus_list[0])\n","        \n","    optimizer = optim.Adam(model.parameters(), lr = opt.lr, betas = (0.9, 0.999), eps=1e-8)\n","    \n","    for epoch in range(opt.start_iter, opt.nEpochs +1):\n","        train(epoch)\n","        #learning rate decay\n","        if (epoch+1) % (opt.nEpochs/2) == 0:\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] /= 10.0\n","            print('Learning rate decay : lr={}'.format(optimizer.param_groups[0]['lr']))\n","        \n","        if (epoch+1) % (opt.snapshots) == 0:\n","            checkpoint(epoch) "],"metadata":{"id":"SQ5ITlzrjEdm","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"error","timestamp":1649640677358,"user_tz":-540,"elapsed":86893,"user":{"displayName":"정남교","userId":"09026629101721319212"}},"outputId":"ddb6e747-e680-46b2-95ef-e4b4fd72fd73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'batchSize': 32, 'lr': 0.001, 'upscale_factor': 2, 'patch_size': 64, 'feature_number': 64, 'start_iter': 1, 'nEpochs': 80, 'snapshots': 20, 'data_dir': '/content/gdrive/My Drive/study/SRCNN/data/train/', 'hr_train_dataset': 'DIV2K_train_HR', 'model_type': 'VDSR', 'save_folder': '/content/gdrive/My Drive/study/SRCNN/weights/', 'pretrained_sr': '/content/gdrive/My Drive/study/SRCNN/weights/ckpt_diff11_label', 'pretrained': False, 'data_augmentation': False, 'residual': False, 'gpu_mode': True, 'threads': 1, 'seed': 123, 'gpus': 1, 'prefix': 'tpami_residual_filter8'}\n","===> Loading datasets\n","===> Building model  VDSR\n","===> Epoch[1](1/25) : Loss: 0.2987 || Timer: 0.7361 sec.\n","===> Epoch[1](2/25) : Loss: 0.1969 || Timer: 0.0050 sec.\n","===> Epoch[1](3/25) : Loss: 0.0813 || Timer: 0.0043 sec.\n","===> Epoch[1](4/25) : Loss: 0.0628 || Timer: 0.0044 sec.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0700b2775458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEpochs\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m#learning rate decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-0700b2775458>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#시작 인덱스(i)를 1부터 세겠다는 뜻\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicubic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#torch.autograd.Variable 하는 이유??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"RrVK3WpKi5gJ"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"VqXXm0zaixQs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649743777457,"user_tz":-540,"elapsed":4313,"user":{"displayName":"정남교","userId":"09026629101721319212"}},"outputId":"59fe0e78-ea43-4064-8cc0-beaa3cd698d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'testBatchSize': 1, 'self_ensemble': False, 'chop_forward': False, 'gpu_mode': True, 'threads': 1, 'seed': 123, 'gpus': 1, 'upscale_factor': 2, 'input_dir': '/content/gdrive/My Drive/study/VDSR/data/test/', 'test_dataset': 'Set5', 'output': '/content/gdrive/My Drive/study/VDSR/Results/', 'model_type': 'VDSR', 'residual': False, 'model': '/content/gdrive/My Drive/study/VDSR/weights/test03/<built-in function gethostname>_epoch_79.pth'}\n","===> Loading datasets\n","===> Building model\n","Pre-trained SR model is loaded.\n","===> Processing: woman_GT.png || Timer: 0.0054 sec. PSNR : 33.6457\n","===> Processing: baby_GT.png || Timer: 0.0132 sec. PSNR : 36.8398\n","===> Processing: bird_GT.png || Timer: 0.0047 sec. PSNR : 37.5207\n","===> Processing: head_GT.png || Timer: 0.0045 sec. PSNR : 32.0398\n","===> Processing: butterfly_GT.png || Timer: 0.0037 sec. PSNR : 30.6040\n","===> Processing: Fingerprint.png || Timer: 0.0130 sec. PSNR : 32.6451\n","===> Processing: Foreman.png || Timer: 0.0038 sec. PSNR : 38.9281\n","===> Processing: Pepper.png || Timer: 0.0130 sec. PSNR : 34.4377\n","===> Processing: Lena.png || Timer: 0.0129 sec. PSNR : 36.0186\n","===> Processing: House.png || Timer: 0.0037 sec. PSNR : 34.8879\n","===> Processing Done, Average PSNR : 34.7567\n","===>PSNR Variance : 6.1411\n"]}],"source":["from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from functools import reduce\n","from math import log10\n","\n","# from scipy.misc import imsave\n","import scipy.io as sio\n","import time\n","import cv2\n","import easydict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"testBatchSize\": 1, \n","    \"self_ensemble\": False,\n","    \"chop_forward\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 1,\n","    \"seed\": 123,\n","    \"gpus\": 1,\n","    \"upscale_factor\": 2,\n","\n","    \"input_dir\":\"/content/gdrive/My Drive/study/VDSR/data/test/\",  # test dataset 불러올위치\n","    \"test_dataset\": \"Set5\",                             # 사용할 test dataset\n","\n","    \"output\": \"/content/gdrive/My Drive/study/VDSR/Results/\", # 결과영상 저장위치\n","\n","    \"model_type\": \"VDSR\",\n","    \"residual\": False,\n","    \"model\": \"/content/gdrive/My Drive/study/VDSR/weights/test03/<built-in function gethostname>_epoch_79.pth\"})  # test에 사용할 weight 불러올 위치 ac040091dff2_epoch_59.pth\n","#<built-in function gethostname>_epoch_79.pth\n","\n","gpus_list = range(opt.gpus)\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","    \n","torch.manual_seed(opt.seed)\n","criterion = nn.MSELoss()\n","\n","\n","\n","print('===> Loading datasets')\n","test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n","testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n","print('===> Building model')\n","model = VDSR()\n","model = torch.nn.DataParallel(model, device_ids = gpus_list)\n","model.load_state_dict(torch.load(opt.model, map_location=lambda storage, loc : storage))\n","print('Pre-trained SR model is loaded.')\n","\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    criterion = criterion.cuda(gpus_list[0])\n","    \n","\n","    \n","def eval():\n","    avg_psnr = 0\n","    psnr_sq = 0\n","    model.eval()\n","    for batch in testing_data_loader:\n","        with torch.no_grad():\n","            input, bicubic, target,name = Variable(batch[0]), Variable(batch[1]), Variable(batch[2]), batch[3]\n","        if cuda : \n","            input = input.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","            \n","        t0 = time.time()\n","        if opt.chop_forward : \n","            with torch.no_grad():\n","                prediction = chop_forward(input, model, opt.upscale_factor)\n","        else : \n","            if opt.self_ensemble :\n","                with torch.no_grad():\n","                    prediction = x8_forward(input, model)\n","            else : \n","                with torch.no_grad():    \n","                    prediction = model(bicubic)  #현재 모델의 경우 이를 수행\n","        if opt.residual : \n","            prediction = prediction + bicubic\n","        \n","        mse = criterion(prediction, target)\n","        psnr = 10 * log10(1 / mse.item())\n","        avg_psnr += psnr / len(testing_data_loader)\n","        psnr_sq += psnr*psnr\n","    \n","        t1 = time.time()\n","        print(\"===> Processing: %s || Timer: %.4f sec. PSNR : %.4f\" % (name[0], (t1 - t0), psnr))\n","        \n","        save_img(bicubic.cpu().data, \"bicubic_\"+name[0])\n","        save_img(prediction.cpu().data, \"prediction_\"+name[0])\n","        save_img(target.cpu().data, \"target_\"+name[0])\n","        \n","    variance = psnr_sq / len(testing_data_loader) - avg_psnr*avg_psnr\n","    print(\"===> Processing Done, Average PSNR : %.4f\" % (avg_psnr))\n","    print(\"===>PSNR Variance : %.4f\" % (variance))\n","    \n","def save_img(img, img_name):\n","    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n","    # save img\n","    save_dir=os.path.join(opt.output,opt.test_dataset)\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    save_fn = save_dir +'/'+ img_name\n","    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n","\n","#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n","def x8_forward(img, model, precision = 'single'):  #if self_ensemble = True\n","    def _transform(v, op):\n","        if precision != 'single' : \n","            v=v.float()\n","        v2np = v.data.cpu().numpy()  #np array로 바꿔줌\n","        if op == 'vflip' :\n","            tfnp = v2np[:, :, :, ::-1].copy()\n","        elif op == 'hflip':\n","            tfnp = v2np[:, :, ::-1, :].copy()\n","        elif op == 'transpose':\n","            tfnp = v2np.transpose((0, 1, 3, 2)).copy()\n","        \n","        ret = torch.Tensor(tfnp).cuda() #다시 Tensor로 변환\n","        \n","        if precision == 'half': #float16\n","            ret = ret.half()\n","        elif precision == 'double': #float64\n","            ret = ret.double()\n","\n","        with torch.no_grad():\n","            ret = Variable(ret)\n","\n","        return ret\n","            \n","    inputlist = [img]\n","    for tf in 'vflip', 'hflip', 'transpose': #inputlist에 'vflip', 'hflip', 'transpose' 시킨 data를 추가해줌 (augmentation?)\n","        inputlist.extend([_transform(t, tf) for t in inputlist])\n","        \n","    outputlist = [model(aug) for aug in inputlist] #늘어난 inputlist를 model에 넣어준 결과를 outputlist에 저장\n","    for i in range(len(outputlist)): #outputlist의 값들도 augmentation 하는건가???\n","        if i > 3:\n","            outputlist[i] = _transform(outputlist[i], 'transpose')\n","        if i % 4 > 1:\n","            outputlist[i] = _transform(outputlist[i], 'hflip')\n","        if (i % 4) % 2 == 1:\n","            outputlist[i] = _transform(outputlist[i], 'vflip')\n","    output = reduce((lambda x, y : x+y), outputlist) / len(outputlist)   #outputlist안에 data 누적해서 더하고 평균 구함\n","    return output\n","#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n","def chop_forward(x, model, scale, shave=8, min_size=80000, nGPUs=opt.gpus): #if chop_forward = True\n","    b, c, h, w = x.size()\n","    h_half, w_half = h//2, w//2\n","    h_size, w_size = h_half + shave, w_half + shave   #chop 하는 size\n","    inputlist = [\n","        x[:, :, 0:h_size, 0:w_size],                       #4 방향 chop\n","        x[:, :, 0:h_size, (w - w_size):w],\n","        x[:, :, (h - h_size):h, 0:w_size],\n","        x[:, :, (h - h_size):h, (w - w_size):w]\n","    ]\n","    if w_size * h_size < min_size:\n","        outputlist = []\n","        for i in range(0, 4, nGPUs):\n","            with torch.no_grad():\n","                input_batch = torch.cat(inputlist[i:(i + nGPUs)], dim=0)\n","            if opt.self_ensemble:\n","                with torch.no_grad():\n","                    output_batch = x8_forward(input_batch, model)\n","            else:\n","                with torch.no_grad():\n","                    output_batch = model(input_batch)\n","            outputlist.extend(output_batch.chunk(nGPUs, dim=0))\n","    else : \n","        outputlist = [\n","            chop_forward(patch, model, scale, shave, min_size, nGPUs)\n","            for patch in inputlist\n","        ] #회귀형 구조로 min_size 보다 작을때까지 진행시켜주며 outputlist에 추가시켜준다\n","        \n","    h, w = scale * h, scale * w\n","    h_half, w_half = scale * h_half, scale * w_half\n","    h_size, w_size = scale * h_size, scale * w_size\n","    shave *= scale\n","    \n","    with torch.no_grad():\n","        output = Variable(x.data.new(b, c, h, w))\n","#outputlist에 저장된 이미지들을 upscale 시킨 크기로 다시 chop해서 output에 저장(처음 x가 downscale된 상태로 들어옴)\n","    output[:, :, 0:h_half, 0:w_half] \\\n","        = outputlist[0][:, :, 0:h_half, 0:w_half]\n","    output[:, :, 0:h_half, w_half:w] \\\n","        = outputlist[1][:, :, 0:h_half, (w_size - w + w_half):w_size]\n","    output[:, :, h_half:h, 0:w_half] \\\n","        = outputlist[2][:, :, (h_size - h + h_half):h_size, 0:w_half]\n","    output[:, :, h_half:h, w_half:w] \\\n","        = outputlist[3][:, :, (h_size - h + h_half):h_size, (w_size - w + w_half):w_size]\n","\n","    return output\n","#-----------------------------------------------------------------------------------------------------------------------------------------------------------------    \n","    \n","if __name__ == '__main__':\n","    eval()"]}]}